.lf 1 /tmp/.doc
.\" use: groff -pte -me | lpr
.\" or : pic | tbl | eqn | ditroff -me
.\"
.\"	"@(#)bibmac.me	2.2	9/9/83";
.de IP
.ip \\$1 \\$2
..
.de LP
.lp
..
.\"	@(#)bmac.std	2.2	9/9/83;
.\" standard format troff commands
.\" citation formatting strings
.ds [[ [
.ds ]] ]
.ds ], ,\|
.ds ]- -
.ds [. " \&
.ds .] .
.ds [, " \&
.ds ,] ,
.ds [? " \&
.ds ?] ?
.ds [: " \&
.ds :] :
.ds [; " \&
.ds ;] ;
.ds [! " \&
.ds !] !
.ds [" " \&
.ds "] \&"
.ds [' " \&
.ds '] '
.ds [< " \&
.ds >]
.\" reference formmating strings
.ds a] " \&
.ds b] , \&
.ds c] , \&
.ds n] "\& and \&
.ds m] "\& and \&
.ds p] .
.\" reference formmating macros
.de s[   \" start reference
.nh
.IP [\\*([F] 5m
..
.de e[   \" end reference
.[-
..
.de []   \" start to display collected references
.LP
..
.de ][   \" choose format
.ie !"\\*([J"" \{\
.    ie !"\\*([V"" .nr t[ 1    \" journal
.    el            .nr t[ 5    \" conference paper
.\}
.el .ie !"\\*([B"" .nr t[ 3    \" article in book
.el .ie !"\\*([R"" .nr t[ 4    \" technical report
.el .ie !"\\*([I"" .nr t[ 2    \" book
.el                .nr t[ 0    \" other
.\\n(t[[
..
.de 0[   \" other
.s[
.if !"\\*([A"" \\*([A\\c
.if !"\\*([T"" , \\*([T\\c
.if !"\\*([V"" , Vol. \\*([V\\c
.if !"\\*([O"" , \\*([O\\c
.if !"\\*([D"" , \\*([D\\c
\&.
.e[
..
.de 1[ \" journal article
.s[
.if !"\\*([A"" \\*([A,
.if !"\\*([T""  \\*([T,
\\fI\\*([J \\*([V\\fP\c
.if !"\\*([N"" ,\\*([N
.if !"\\*([D"" (\\*([D)\c
.if !"\\*([P"" , \\*([P\c
.if !"\\*([I"" , \\*([I\c
\\&.
.if !"\\*([O"" \\*([O.
.e[
..
.de 2[ \" book
.s[
.ie !"\\*([A"" \\*([A,
.el .if !"\\*([E"" \{\
.       ie \\n([E-1 \\*([E, eds.,
.       el \\*([E, ed.,\}
.if !"\\*([T"" \\fI\\*([T\\fP,
.rm a[
.if !"\\*([I"" .ds a[ \\*([I
.if !"\\*([C"" \{\
.       if !"\\*(a["" .as a[ , \\&
.       as a[ \\*([C\}
.if !"\\*([D"" \{\
.       if !"\\*(a["" .as a[ , \\&
.       as a[ \\*([D\}
\\*(a[.
.if !"\\*([G"" Gov. ordering no. \\*([G.
.if !"\\*([O"" \\*([O.
.e[
..
.de 3[ \" article in book
.s[
.if !"\\*([A"" \\*([A,
.if !"\\*([T"" \\*([T,
in \\fI\\*([B\\fP\c
.if !"\\*([V"" , vol. \\*([V
.if !~\\*([E~~ \{\
.       ie , \\n([E-1  \\*([E (editors)\c
.       el , \\*([E (editor)\c\}
.if !"\\*([I"" , \\*([I\c
.if !"\\*([C"" , \\*([C\c
.if !"\\*([D"" , \\*([D\c
.if !"\\*([P"" , \\*([P\c
\\&.
.if !"\\*([O"" \\*([O.
.e[
..
.de 4[ \" report
.s[
.if !"\\*([A"" \\*([A,
.if !~\\*([E~~ \{\
.       ie \\n([E-1 \\*([E, editors.
.       el \\*([E, editor.\}
\\*([T,
\\*([R\c
.if !"\\*([G"" \& (\\*([G)\c
.if !"\\*([I"" , \\*([I\c
.if !"\\*([C"" , \\*([C\c
.if !"\\*([D"" , \\*([D\c
\\&.
.if !"\\*([O"" \\*([O.
.e[
..
.de 5[ \" conference paper
.s[
.if !"\\*([A"" \\*([A,
.if !"\\*([T"" \\*([T,
\\fI\\*([J\\fP,
.if !"\\*([C"" \\*([C,
.if !"\\*([D"" \\*([D\c
.if !"\\*([P"" , \\*([P\c
\\&.
.if !"\\*([O"" \\*([O.
.e[
..
.de [-   \" clean up after yourself
.rm [A [B [C [D
.rm [E [F [G
.rm [I [J [K
.rm [N [O [P
.rm [R [T
.rm [V [W
..
.\"	@(#)bmac.std	2.2	8/24/83;
.\" standard format troff commands
.\" citation formatting strings
.ds [[ [
.ds ]] ]
.ds ], ,\|
.ds ]- -
.ds [. " \&
.ds .] .
.ds [, " \&
.ds ,] ,
.ds [< " \&
.ds >]
.\" reference formmating strings
.ds c] , \&
.ds n] "" and \&
.ds m] "" and \&
.ds a] " \&
.\" reference formmating macros
.de s[   \" start reference
.nh
.IP [\\*([F] 5m
..
.de e[   \" end reference
.[-
..
.de []   \" start to display collected references
.SH
References
.LP
..
.de ][   \" choose format
.ie !"\\*([J"" \{\
.    ie !"\\*([V"" .nr t[ 1    \" journal
.    el            .nr t[ 5    \" conference paper
.\}
.el .ie !"\\*([B"" .nr t[ 3    \" article in book
.el .ie !"\\*([R"" .nr t[ 4    \" technical report
.el .ie !"\\*([I"" .nr t[ 2    \" book
.el                .nr t[ 0    \" other
.\\n(t[[
..
.de 0[   \" other
.s[
.if !"\\*([A"" \\*([A,
.if !"\\*([T"" \\*([T,
.if !"\\*([O"" \\*([O\c
.if !"\\*([D"" , \\*([D\c
\&.
.e[
..
.de 1[ \" journal article
.s[
.if !"\\*([A"" \\*([A,
.if !"\\*([T"" \\*([T,
\\fI\\*([J \\*([V\\fP,
.if !"\\*([N"" \\*([N
.if !"\\*([D"" (\\*([D),
.if !"\\*([P"" \\*([P\c
.if !"\\*([I"" , \\*([I\c
\\&.
.if !"\\*([O"" \\*([O.
.e[
..
.de 2[ \" book
.s[
.ie !"\\*([A"" \\*([A,
.el .if !"\\*([E"" \{\
.       ie \\n([E-1 \\*([E, eds.,
.       el \\*([E, ed.,\}
.if !"\\*([T"" \\fI\\*([T\\fP,
.rm a[
.if !"\\*([I"" .ds a[ \\*([I
.if !"\\*([C"" \{\
.       if !"\\*(a["" .as a[ , \\&
.       as a[ \\*([C\}
.if !"\\*([D"" \{\
.       if !"\\*(a["" .as a[ , \\&
.       as a[ \\*([D\}
\\*(a[.
.if !"\\*([G"" Gov. ordering no. \\*([G.
.if !"\\*([O"" \\*([O.
.e[
..
.de 3[ \" article in book
.s[
.if !"\\*([A"" \\*([A,
.if !"\\*([T"" \\*([T,
in \\fI\\*([B\\fP,
.if !"\\*([V"" vol. \\*([V,
.if !"\\*([E"" \\*([E (ed.),
.if !"\\*([I"" \\*([I,
.if !"\\*([C"" \\*([C,
.if !"\\*([D"" \\*([D\c
.if !"\\*([P"" , \\*([P\c
\\&.
.if !"\\*([O"" \\*([O.
.e[
..
.de 4[ \" report
.s[
.if !"\\*([A"" \\*([A,
\\*([T,
\\*([R\c
.if !"\\*([G"" \& (\\*([G)\c
.if !"\\*([I"" , \\*([I\c
.if !"\\*([C"" , \\*([C\c
.if !"\\*([D"" , \\*([D\c
\\&.
.if !"\\*([O"" , \\*([O.
.e[
..
.de 5[ \" conference paper
.s[
.if !"\\*([A"" \\*([A,
.if !"\\*([T"" \\*([T,
\\fI\\*([J\\fP,
.if !"\\*([C"" \\*([C\c
.if !"\\*([D"" , \\*([D\c
.if !"\\*([P"" , \\*([P\c
\\&.
.if !"\\*([O"" , \\*([O.
.e[
..
.de [-   \" clean up after yourself
.rm [A [B [C [D
.rm [E [F [G
.rm [I [J [K
.rm [N [O [P
.rm [R [T
.rm [V [W
..
.lf 1 ./head
.if t \{ \
.ie rletter .pl 11i	\" page length letter
.el .pl 29.7c	\" page length DIN A4
.po 2.5c	\" page offset (left margin)
.ll 17.0c	\" line length
.lt 17.0c	\" title length
.nr LL 17.0c
.nr )l 29.7c
.nr pp 12
.nr sp 12
.nr tp 12	\" title point size
.nr fp 10	\" foot note point size
.nr bi 4n	\" block indentation
.hc ~		\" hyphenation character
.
.		\" Umlauts and sharp s
.ie "\n(.g"1" \
\{\
.nr $r \n(.v*100+\n(.sp-1u/\n(.sp
.nr $r 112	\" factor for vertical spacing, orig. value = 120
.ds A \(:A
.ds O \(:O
.ds U \(:U
.ds a \(:a
.ds o \(:o
.ds u \(:u
.ds s \(ss
.\}
.el \
\{\
.nr $r 9	\" factor for vertical spacing
.ds A \(A:
.ds O \(O:
.ds U \(U:
.ds a \(a:
.ds o \(o:
.ds u \(u:
.ds s \(ss
.\}
.nr $R \n($r
.sz 12		\" font size
.		\"  UMLAUT  \*:u, etc.
.ds : \v'-0.6m'\h'(1u-(\\n(.fu%2u))*0.13m+0.06m'\z.\h'0.2m'\z.\h'-((1u-(\\n(.fu%2u))*0.13m+0.26m)'\v'0.6m'
.\}
.
.if n \{ \
.po 0		\" page offset (left margin)
.ll 78		\" line length
.lt 78		\" title length
.nr $r 4	\" factor for vertical spacing
.nr $R \n($r
.hc ~		\" hyphenation character
.		\" Umlaute und scharfes s
.
.\" .pl 1050
.ds A Ä
.ds O Ö
.ds U Ü
.ds a ä
.ds o ö
.ds u ü
.ds s ß
.
.ds A Ae
.ds O Oe
.ds U Ue
.ds a ae
.ds o oe
.ds u ue
.ds s ss
.
.\}
.
.de _
\&\\$1\l'|0\(ul' \\$2
..
.ds d \h'0.12c'	\" space with width of a dot
.
.de FT		\" font for programs
.ft C
.sz -2
..
.
.de FR
.ft R
.sz +2
..
.de tt
.@E
.ft C
.\" .sz -2
.if \\n(.$ \&\\$1\f\\*(_F\\$2
..
.
.de []		\" start to display collected references
.uh References
.lp
..
.
.de $0		\" collect table of contents
.(x
.ta 2c
.ie '\\$2''	\\$1
.el \\$2.	\\$1
.)x
..
.
.de np
.nr $p +1
.ip \\n($p.
..
.nr y4 1900+\n(yr
.
.de SH
.sp 0.5
.in -3
.b \\$1
.sp 0.5
.in +3
..
.
.de PP
.sp 0.5
..
.
.de IP
.ip \\$1 \\$2
..
.
.de I
.i \\$1
..
.
.de TH
..
.
.de UL
\&\\$1\l'|0\(ul'\\$2
..
.
.de PS
.sp 0.5
..
.
.de PE
.sp 0.5
..
.
.de T0
.b " "
.sp 1c
.ta 9c
.ft R
.sz 12
\l'17.0c'
.nf
..
.
.de T1
\l'17.0c'
.ie rletter .sp 11.0c
.el .sp 12.5c
\l'17.0c'
.ft H
.nf
 
	DR. JOSEF GROSCH
 
	COCOLAB - DATENVERARBEITUNG
 
	GERMANY
 
.r
\l'17.0c'
..
.
.de T2
.bp
.oh ''\\$1'%'
.eh ''\\$1'%'
.ce 99
.b " "
.sz 20
.ie rletter .sp 0
.el .sp 2
.b "Cocktail"
.sp 2
Toolbox for Compiler Construction
.sp 2
.sz 12
\l'15c'
.sp 2
.sz 16
.b "\\$2"
.sp 2
\\$3
.sp 2
.sz 14
\\$4
.sp 2
.sz 12
\l'15c'
.sp 2
Document No. \\$5
.sp 2
Copyright \(co \\$6 Dr. Josef Grosch
.sp 2
Dr. Josef Grosch
CoCoLab - Datenverarbeitung
Breslauer Str. 64c
76139 Karlsruhe
Germany
.sp 0.5
.hc
Phone: +49-721-91537544
Fax: +49-721-91537543
Email: grosch@cocolab.com
.ce 0
.fi
..
.lf 294 /tmp/.doc
.EQ
delim off
.EN
.T0

	Efficient Evaluation of
	Well-Formed Attribute Grammars
	And Beyond

	J. Grosch


.T1
.T2 "" "Efficient Evaluation of Well-Formed Attribute Grammars And Beyond" "Josef Grosch" "Oct. 15, 1992" 31 1994
.bp 1
.ce 99
.b "Efficient Evaluation of Well-Formed Attribute Grammars And Beyond"
.ce 0
.sp
.EQ
gsize 12
delim @@
.EN
.uh Abstract
.lp
This paper is concerned with the evaluation of well-formed attribute grammars as support
for semantic analysis. This is the largest class of attribute grammars, which does not
impose any restrictions. A data structure and an algorithm are described which are
efficient, both in terms of space and time. Attribute grammars are extended from the
decoration of trees to the decoration of graphs and to the access of non-local attributes.
Experimental results are presented that compare the space and time behaviour of evaluators
for well-formed attribute grammars and ordered attribute grammars.
.sp 0.5
.b Keywords
well-formed attribute grammars, attribute evaluation
.sp 1
.sh 1 Introduction
.lp
.\" A compiler for a programming language usually has two parts: an analysis part and a
.\" synthesis part. The analysis part comprises lexical analysis, syntax analysis, and
.\" semantic analysis. The main task of the synthesis part is code-generation.
.\" The implementation of lexical and syntactical analysis is well supported by appropriate
.\" specification techniques such as regular expressions and context-free grammars and by
.\" tools for scanner and parser generation.
One possibility to support the definition and implementation of semantic analysis in a
systematic and formal manner is the use of an attribute grammar
\*([[Knu68\*(]].
From this kind of specification, attribute evaluators that implement semantic analysis can
be generated automatically by appropriate tools.
After 25 years of research in the area of attribute grammars, tools that process this kind
of specification are still not as popular as e. g. scanner and parser generators.
Some reasons for this are that in the past attribute evaluators consumed too much memory
and too much run time or they handled restricted classes of attribute grammars, only.
Now even well-formed attribute grammars, the largest class of attribute grammars,
can be evaluated efficiently, as will be shown in this paper.
.pp
Pure attribute grammars advocate a functional style. Computation rules describe the
computation of attribute values by expressions that may depend on other attribute values.
All those dependencies must be given explicitly. There are neither global attributes
nor side-effects. These functional dependencies are the basis for checks
that can be performed automatically. Attribute grammars can be checked for the
correct use of synthesized and inherited attributes, for completeness, and for the absence
of cyclic dependencies. An attribute grammar is complete if there are computation rules for
all attributes. An attribute grammar has cyclic dependencies if there are attributes that
depend on themselves, either directly or indirectly. Furthermore, the dependencies among
the attributes allow the determination of an evaluation order for the attributes. While the
checks that can be performed on an attribute grammar are certainly valuable, the automatic
determination of an evaluation order is attractive only at the first glance. It works well
for small applications with today's technology.
.pp
However, our experience with large applications using state of the art attribute grammar
tools shows that there is no real relief of the burden to worry about the evaluation
order. Our recent projects involved attribute grammars for Modula-2\*([<\*([[Mar90\*(]]\*(>], Modula-3\*([<\*([[Kie91\*(]]\*(>], and the robot programming
language IRL\*([<\*([[IRL92\*(]]\*(>]. Today's attribute grammar tools usually handle restricted classes
of attribute grammars such as for example ordered attribute grammars
\*([[Kas80\*(]] where the evaluation order can be determined
statically during generation time. It is argued that those restrictions are necessary in
order to achieve efficient attribute evaluation. In larger applications often cyclic
dependencies among the attributes are introduced by the closure algorithms which are due
to those restricted classes of attribute grammars. In order to remove those cyclic
dependencies it is necessary to worry quite a lot about evaluation order and to introduce
additional attributes along with additional (maybe dummy) computations. These steps solve
the problems with the cycles but lead to rather complicated attribute grammars.
In our experience, those grammars degrade from formal problem specifications to problem
implementations which are hard to understand and to maintain\*([<\*([[Mar90\*(]]\*(>].
.pp
From the drawbacks mentioned above we conclude that substantial improvements are necessary
in the area of attribute grammars. Therefore we propose to use the class of well-formed
attribute grammars, which is the largest class of useful attribute grammars.
An attribute grammar is well-formed or non circular if for every tree the dependency
relation among all attributes is cycle free.
This approach retains the advantages of attribute grammars mentioned before such as
formal consistency checks and the automatic determination of the order of the
computations. Smaller classes such as ordered attribute grammars are considered to be too
restrictive because one has still to bother with the evaluation order. 
Naturally, evaluators for
well-formed attribute grammars are not as efficient as those for e. g. ordered attribute
grammars. For ordered attribute grammars the evaluation order (visit sequence) can be
determined statically during the generation of the evaluator. For well-formed attribute
grammars the evaluation order must be determined dynamically during the run time of the
evaluator. Of course, there is a trade-off between expressive power and efficiency.
This paper shows that well-formed attribute grammars can be evaluated efficiently both in
terms of space and time. Compared to ordered attribute grammars the increased consumption
of memory and run time is relatively small and it is tolerable with today's hardware.
.pp
Furthermore, the attribution
of trees will be extended to the attribution of graphs. While conventional attribute
grammars base computations only on attributes local to a grammar rule, we will allow the
access of non-local attributes. The processing of graphs and access to non-local
attributes is of interest for example for the handling of symbol tables in an attribute
grammar style. With the latter features the foundations of conventional attribute grammars
are left and this explains the word
.i beyond
in the title. It turns out that these features fit together nicely with the evaluation of
well-formed attribute grammars.
.pp
This paper is organized as follows:
Section 2 describes the data structure of the trees to be decorated with attributes.
Section 3 presents the principle of the algorithm for the evaluation of well-formed
attribute grammars.
Section 4 applies several transformation steps to this algorithm using partial evaluation
and turns it into a more efficient version.
Section 5 describes the extensions concerning graphs and access to non-local attributes.
Section 6 reports experimental results.
Section 7 describes related research.
Section 8 contains concluding remarks.
.sh 1 "Data Structure"
.lp
They key idea of our approach is to use a recursive attribute evaluator that computes
attributes by need\*([<\*([[DJL88\*(]]\*(>].
The run time of such an evaluator is theoretically time-optimal. It is sublinear
in the size of the tree because it computes
only those attributes necessary for the final result. However, the stack space is not
limited by the height of the tree. We implement a procedure C (t, i) which computes the i-th
attribute of a rule that is represented by a tree node at the address t and which stores the
result in the tree. Before the computation of an attribute, the attributes it depends on
are computed by appropriate recursive calls of this procedure. Afterwards its value can be
computed and stored, because all information necessary is locally available within the
context of the current rule. One attribute may be used several times but of course it
suffices to compute it only once.
.\" This is achieved by a bit that indicates that the attribute has already been computed.
.pp
There are basically two possibilities for the underlying data structure: One can either use
the (abstract) syntax tree or the graph of dependencies among the attributes.
We have chosen the first alternative because it promises to be space efficient.
The properties of the data structure are enumerated first and explained in more detail
afterwards. Fig. 1 illustrates the internal representation of a grammar rule such as
@ X sub 0 ~=~ X sub 1~ X sub 2~ X sub 3 @ in the tree. The node @ n sub 0 @ stands for the
left-hand side and the nodes @ n sub 1 @, ..., @ n sub 3 @ stand for the right-hand side.
In this example it is assumed that every node has three children and four attributes.
The attributes of all
nodes @ n sub 0 @, ..., @ n sub 3 @ would be accessible in the context of this rule.
.(z L
.PS
scale	= 2.54
boxwid	= 2.4
boxht	= 0.6

define nbox #
	box $1
	$2  rjust at last box.w - (0.2, 0)
	$3  ljust at last box.e + (0.2, 0)
	down
#

	down
N0:	box "RuleType"
	box "IsComp"
	box "Offset"
	box "Parent"
C1:	box "Child 1"
	box "..."
C30:	box "Child 3"
	nbox("Attribute 1", "1", "")
	box "..." at C30.c - (0, 2 * boxht)
	nbox("Attribute 4", "4", "")

N1:	box "RuleType" at last box + (-2 * boxwid, -2 * boxht)
	box "IsComp"
	box "Offset = 4"
P1:	box "Parent"
	box "Child 1"
D:	box "..."
C31:	box "Child 3"
	nbox("Attribute 1", "5", "1")
	box "..." at C31.c - (0, 2 * boxht)
	nbox("Attribute 4", "8", "4")

N3:	box "RuleType" at N1 + (4 * boxwid, 0)
	box "IsComp"
	box "Offset = 12"
P3:	box "Parent"
	box "Child 1"
	box "..."
C33:	box "Child 3"
	nbox("Attribute 1", "13", "1")
	box "..." at C33.c - (0, 2 * boxht)
	nbox("Attribute 4", "16", "4")

	box "..." invis at D + (2 * boxwid, 0)
	arrow from P1.e right boxwid/2 then up 14*boxht then to N0.w
	arrow from P3.w left  boxwid/2 then up 14*boxht then to N0.e
	arrow from C1.w to N1.n
	arrow from C30.e to N3.n
	move to N1.w + (- boxwid, 0)

	"@ n sub 0 @" rjust at N0.w - (0.2, boxht)
	"@ n sub 1 @" rjust at N1.w - (0.2, 0)
	"@ n sub 3 @" rjust at N3.w - (0.2, 0)
.PE
.sp
.ce
Fig. 1: Data Structure
.)z
.np
Every tree node has pointers referring to all of its children or subtrees.
.np
Every tree node has a pointer referring to its parent node.
.np
All attributes are stored in the tree.
.np
For every attribute there is a bit that indicates whether the attribute is already computed.
.np
All attribute occurrences within a rule are numbered (see below).
.np
Every tree node stores an offset that allows to convert attribute numbers between
different rule contexts.
.pp
The pure syntax tree (1) is not sufficient. It must be augmented by pointers to parent
nodes (2), indicator bits (4), and certain offsets (6) in order to avoid unnecessary
recomputations of attributes and to enable recursive calls that climb up in the
tree. The attribute dependencies are contained implicitly in this structure together with
the knowledge about the dependencies available during generation time.
.pp
The pointers to parent nodes (2) are necessary for the computation of inherited
attributes which are performed in the context of the parent rules.
.pp
The chosen representation has the disadvantage that optimization of
attribute storage is impossible and therefore all attributes have to be stored in the tree
(3). However, this imposes no restriction with today's memory capacities.
The use of a complete dependency graph would allow an optimization that replaces several
attribute instances whose values are copies of each other by a single instance.
.pp
As already mentioned, a bit is maintained for every attribute (4) in order to evaluate the
attribute value only once. All the bits for one node are combined in a bit vector called
.i IsComp .
.pp
All attribute occurrences of the left-hand side and the right-hand side of a rule are
numbered (5). For example, in Fig. 1 the attributes in the context of the tree node
@ n sub 0 @ are numbered from 1 to 16 as given by the numbers to the left of the attribute
fields.
.pp
When the context is changed from a parent node to child node or vice versa then right-hand
side attributes become left-hand side attributes or vice versa. In the new context the
attribute numbers are different. The offset (6) represents the difference between those two
attribute numbers. For example, if the context changes from the node @ n sub 0 @ to one of
its children @ n sub 1 @ or @ n sub 3 @ then the attributes of @ n sub 1 @ or @ n sub 3 @
would receive the numbers given to the right of the attribute fields.
.pp
The data structure for the tree is built in two phases. First, space is allocated for the
tree nodes and pointers to the child nodes are established. This usually happens during
parsing. Second, before attribute evaluation actually starts, a traversal of the tree is
performed that initializes the parent pointers, the indicator bits, and the offsets.
.(z L
.FT
void C (tTree t, int ii)
{
  switch (t->RuleType) {
  ...
  case n:   /* one case for every rule type n                                */
    switch (ii) {
    ...
    case i: /* one case for every attribute number i of rule type n
               that is to be computed in the context of this rule type       */
.sp 0.5
            /* check whether i is already computed:                          */
      if (IN (i, t->IsComp)) return; /* if i is attribute of left-hand  side */
      if (IN (l, t->Child->IsComp)) return; /* l = i - t->Child->Offset      */
                                     /* if i is attribute of right-hand side */
.sp 0.5
            /* one call for every attribute j that attribute i depends on:   */
      C (t, j);          /* if j is synthesized attribute of left-hand  side */
      C (t->Parent, t->Offset + j);
                         /* if j is inherited   attribute of left-hand  side */
      C (t->Child, k);   /* k = j - t->Child->Offset                         */
                         /* if j is synthesized attribute of right-hand side */
      C (t, j);          /* if j is inherited   attribute of right-hand side */
.sp 0.5
            /* compute attribute i:                                          */
      t->Attribute = ...             /* if i is attribute of left-hand  side */
      t->Child->Attribute = ...      /* if i is attribute of right-hand side */
.sp 0.5
            /* mark attribute i as computed:                                 */
      INCL (t->IsComp, i);           /* if i is attribute of left-hand  side */
      INCL (t->Child->IsComp, l);    /* if i is attribute of right-hand side */
      break;
    ...
    }
  ...
  }
}
.FR
.sp
.ce
Fig. 2: Basic Algorithm
.)z
.sh 1 "Basic Algorithm"
.lp
The procedure C (t, i) as the core of an attribute evaluator is generated from an attribute
grammar. It constitutes a directly coded evaluator rather than a table-driven one.
It will compute the attribute with the number i at a tree node with the address t.
The general structure is shown in Fig. 2 using a C-like notation.
It consists of two nested switch statements that discriminate the present rule type and
attribute number. For all those cases there will be a code segment which is structured as
the one given in Fig. 2. First, the indicator bit is checked whether this attribute has
already been computed. Then the availability of the attributes used as arguments for the
current computation is assured by appropriate recursive calls of the procedure C. Then the
attribute is computed and stored in the tree. Finally, the bit is set to indicate that the
attribute has been computed.
.pp
The code scheme in Fig. 2 uses two macros:
IN (b, v) tests whether bit number b is set in the bit-vector v.
INCL (v, b) sets bit number b in the bit-vector v.
The selector names
.i Child
and
.i Attribute
would be replaced by specific names to access child nodes and attributes.
Most of the attribute numbers are constants whose values can be determined at generation
time (i, j, k, l).
.pp
In simple cases the result of an attribute evaluation are the values of the synthesized
attributes at the root node. In this case the evaluation would be started by appropriate
calls of the procedure C for the synthesized attributes of the root. In general, one is
interested in the values of so-called output attributes which may be spread all over the
tree. Output attributes are those attributes that are supposed to hold their value upon
termination of attribute evaluation. For example, the tree and its output attributes might
constitute the input to a succeeding tree transformation using a tool based on
pattern-matching such as
.i puma
\*([[Gro92\*(]]. Moreover, an attribute evaluator has to check
conditions of the attribute values. Conditions can be regarded as boolean output attributes
whose values do not have to be stored. The above considerations explain the necessity of an
evaluator routine E that traverses those subtrees that may contain output attributes or
conditions and that triggers their evaluation by appropriate calls of the procedure C. The
procedure E can be optimized using tail recursion.
.pp
The presented version of the procedure C works, however, it has a few drawbacks. In real
applications it could become tremendously large and it may exceed compiler restrictions.
Furthermore, it can be made more efficient as shown in the next section.
.if 0 \{ \
.bp
.nf
.FT
void I (tTree t, int ii)
{
  switch (t->RuleType) {
  ...
  case n:   /* one case for every rule type n                                */
    switch (ii) {
    ...
    case i: /* one case for every inherited attribute number i of rule type
               n that is to be computed in the context of this rule type     */
.sp 0.5
            /* check whether i is already computed                           */
      if (IN (l, t->Child->IsComp)) return; /* l = i - t->Child->Offset      */
.sp 0.5
            /* one call for every attribute j that attribute i depends on:   */
      S (t, j);          /* if j is synthesized attribute of left-hand  side */
      I (t->Parent, t->Offset + j);
                         /* if j is inherited   attribute of left-hand  side */
      S (t->Child, k);   /* k = j - t->Child->Offset                         */
                         /* if j is synthesized attribute of right-hand side */
      I (t, j);          /* if j is inherited   attribute of right-hand side */
.sp 0.5
      t->Child->Attribute = ...       /* compute attribute i                 */
      INCL (t->Child->IsComp, l);     /* mark attribute i as computed        */
      break;
    ...
    }
  ...
  }
}
.FR
.nf
.FT
void S (tTree t, int ii)
{
  switch (t->RuleType) {
  ...
  case n:   /* one case for every rule type n                                */
    switch (ii) {
    ...
    case i: /* one case for every synthesized attribute number i of rule type
               n that is to be computed in the context of this rule type     */
.sp 0.5
            /* check whether i is already computed                           */
      if (IN (i, t->IsComp)) return;
.sp 0.5
            /* one call for every attribute j that attribute i depends on:   */
      S (t, j);          /* if j is synthesized attribute of left-hand  side */
      I (t->Parent, t->Offset + j);
                         /* if j is inherited   attribute of left-hand  side */
      S (t->Child, k);   /* k = j - t->Child->Offset                         */
                         /* if j is synthesized attribute of right-hand side */
      I (t, j);          /* if j is inherited   attribute of right-hand side */
.sp 0.5
      t->Attribute = ...                     /* compute attribute i          */
      INCL (t->IsComp, i);                   /* mark attribute i as computed */
      break;
    ...
    }
  ...
  }
}
.FR
.bp
.nf
.FT
typedef void (* tP) (tTree);
tP I [] = { 0, I_1, I_2, ... };
.sp 0.5
void I_i (tTree t)   /* one procedure for every inherited attribute number i */
{
  switch (t->RuleType) {
  ...
  case n:   /* one case for every rule type n                                */
.sp 0.5
            /* check whether i is already computed                           */
    if (IN (l, t->Child->IsComp)) return; /* l = i - t->Child->Offset        */
.sp 0.5
            /* one call for every attribute j that attribute i depends on:   */
    S_j (t);             /* if j is synthesized attribute of left-hand  side */
    I [t->Offset + j](t->Parent);
                         /* if j is inherited   attribute of left-hand  side */
    S_k (t->Child);      /* k = j - t->Child->Offset                         */
                         /* if j is synthesized attribute of right-hand side */
    I_j (t);             /* if j is inherited   attribute of right-hand side */
.sp 0.5
    t->Child->Attribute = ...                /* compute attribute i          */
    INCL (t->Child->IsComp, l);              /* mark attribute i as computed */
    break;
  ...
  }
}
.FR
.nf
.FT
void S_i (tTree t) /* one procedure for every synthesized attribute number i */
{
  if (IN (i, t->IsComp)) return;      /* check whether i is already computed */
  switch (t->RuleType) {
  ...
  case n:   /* one case for every rule type n                                */
.sp 0.5
            /* one call for every attribute j that attribute i depends on:   */
    S_j (t);             /* if j is synthesized attribute of left-hand  side */
    I [t->Offset + j](t->Parent);
                         /* if j is inherited   attribute of left-hand  side */
    S_k (t->Child);      /* k = j - t->Child->Offset                         */
                         /* if j is synthesized attribute of right-hand side */
    I_j (t);             /* if j is inherited   attribute of right-hand side */
.sp 0.5
    t->Attribute = ...                       /* compute attribute i          */
    break;
  ...
  }
  INCL (t->IsComp, i);                       /* mark attribute i as computed */
}
.FR
.bp
.nf
.\}
.(z L
.FT
typedef void (* tP) (tTree);
tP I [] = { 0, I_1, I_2, ... };
.sp 0.5
void I_i (tTree t)   /* one procedure for every inherited attribute number i */
{
  switch (t->RuleType) {
  ...
  case n:                                  /* one case for every rule type n */
.sp 0.5
            /* one call for every attribute j that attribute i depends on:   */
    if (! IN (j, t->IsComp)) S_j (t);
                         /* if j is synthesized attribute of left-hand  side */
    if (! IN (j, t->IsComp)) I [t->Offset + j](t->Parent);
                         /* if j is inherited   attribute of left-hand  side */
    if (! IN (k, t->Child->IsComp)) S_k (t->Child);/* k=j - t->Child->Offset */
                         /* if j is synthesized attribute of right-hand side */
    if (! IN (k, t->Child->IsComp)) I_j (t);
                         /* if j is inherited   attribute of right-hand side */
.sp 0.5
    t->Child->Attribute = ...              /* compute attribute i            */
    INCL (t->Child->IsComp, l);            /* mark attribute i as computed   */
    break;                                 /* l = i - t->Child->Offset       */
  ...
  }
}
.sp 0.5
void S_i (tTree t) /* one procedure for every synthesized attribute number i */
{
  switch (t->RuleType) {
  ...
  case n:                                  /* one case for every rule type n */
.sp 0.5
            /* one call for every attribute j that attribute i depends on:   */
    if (! IN (j, t->IsComp)) S_j (t);
                         /* if j is synthesized attribute of left-hand  side */
    if (! IN (j, t->IsComp)) I [t->Offset + j](t->Parent);
                         /* if j is inherited   attribute of left-hand  side */
    if (! IN (k, t->Child->IsComp)) S_k (t->Child);/* k=j - t->Child->Offset */
                         /* if j is synthesized attribute of right-hand side */
    if (! IN (k, t->Child->IsComp)) I_j (t);
                         /* if j is inherited   attribute of right-hand side */
.sp 0.5
    t->Attribute = ...                     /* compute attribute i            */
    break;
  ...
  }
  INCL (t->IsComp, i);                     /* mark attribute i as computed   */
}
.FR
.sp
.ce
Fig. 3: Optimized Algorithm
.)z
.sh 1 "Optimized Algorithm"
.lp
Several transformation steps can be applied to the basic algorithm of the previous section
resulting in a more handy and efficient version:
.pp
First, the procedure C can be split in two procedures I and S that handle inherited and
synthesized attributes separately. This reduces the procedure size to around the half.
.pp
Second, the procedures I and S can be split into two sets of procedures with elements I_i
and S_i. This is done by applying partial evaluation to I and S with respect to the second
arguments for all existing attribute numbers. This step drastically reduces the procedure
sizes. Only one argument needs to be passed to the procedures instead of two. One of the
two switch statements disappears. In some cases the remaining switch statement contains
only one case and then it can be removed, too.
.pp
In all cases but one it is statically known which procedure of the two sets has to be
called. In the case of an inherited attribute of the left-hand side the procedure to
be called depends on the offset of the current node which is known only during run time.
This can be solved by an array of procedures I which is initialized such that I [i] refers
to I_i. Then those calls access the array with a dynamically computed index in order to
determine the required procedure. The calls have the following form:
.(b
.FT
I [t->Offset + j] (t->Parent);
.)b
.pp
Third, the check whether an attribute is already computed can be moved from inside the
procedures to all the places immediately before the call of the procedures. This increases
code size but decreases run time by avoiding unnecessary procedure calls if there is more
than one use of an attribute.
.pp
Fourth, the handling of conditions can be optimized in several respects:
No indicator bits are necessary for conditions because the results are neither stored nor
can they be used.
The calls of the procedures S_i can be saved if the code segments for conditions are moved
from the procedures S_i into the evaluator routine E.
If the conditions are checked after the evaluation of the output attributes it suffices to
trigger the evaluation of the non-output attributes used as arguments in the conditions.
If there are several conditions for one rule type and some use one non-output attribute as
argument then it suffices to trigger its evaluation only once.
.pp
The resulting structure of the procedures I_i and S_i is presented in Fig. 3.
.sh 1 "Extensions to Attribute Grammars"
.lp
Conventionally, attribute evaluation is performed on trees. It can be extended to handle
graphs as well, if several problems are suitably solved.
.pp
First, the driver routine for attribute evaluation E has to handle at least strongly
connected, directed graphs. In order to avoid infinite loops arising from cycles in the
graph a depth first traversal of the graph can be performed using a simple algorithm with a
mark bit.
.pp
Second, in graphs a node can have several parent nodes. If there are synthesized attributes
then it suffices to compute them upon the first visit coming from one of the parent nodes.
When further visits coming from other parents require this value it needs not to be computed
again and this is assured by the mechanism with the indicator bit. Here attribute
evaluation on graphs and our evaluator for well-formed attribute grammars fit together,
nicely.
.pp
If there are inherited attributes then it must be decided which of the parent nodes should
compute the value. We defined to select one as the "real" parent and thus being responsible
for the evaluation of inherited attributes. The real parent node is selected during the
initialization phase when the parent pointers are established.
.pp
Third, our implementation supports higher-order attribute grammars (HAGs)
\*([[VSK89\*(],Vog93\*(]]
which allow tree-valued attributes (pointers to
subtrees) and that subtrees may be created dynamically during attribute evaluation.
This can be realized relatively simple by treating pointers to children like attributes
and by including them in the dependency analysis. In combination with the evaluation of
well-formed attribute grammars it is necessary to initialize dynamically created subtrees
with parent pointers, offests, and indicator bits.
.pp
Fourth, the HAG philosophy leads to the access of non-local attributes. For example, one
possibility for the implementation of a symbol table is to use the abstract syntax tree
itself as data structure. A symbol table entry would be accessed via a pointer to the node
representing a declaration. At the applied occurrence of an identifier a lookup in the symbol
table is performed that yields an attribute which is a pointer to a declaration. Of course,
one is interested in accessing properties of this symbol table entry which is equivalent to
the access of attributes of a node that is outside the context of the current rule.
We defined the following syntax for this non-local attribute access:
.(b
.FT
REMOTE address => rule_type : attribute
.)b
It specifies the address of a tree node which is supposed to have a certain rule type and
the name of the attribute. Again this feature can be nicely implemented in our evaluator
for well-formed attribute grammars. The rule type and the attribute name allow to
determine the evaluation procedure and the address supplies the argument to the call. This
call assures that the attribute is evaluated. Then its value can be accessed by
dereferencing the pointer (address) appropriately. The dynamic behaviour of the evaluator
allows the computation of non-local attributes without any particular extensions because
it can be requested to compute any attribute.
.sh 1 "Experimental Results"
.lp
The algorithm described in the previous sections has been implemented by extending
the generator for attribute evaluators
.i ag
\*([[Gro\*(]] to produce evaluators for well-formed attribute grammars. The tool
.i ag
is part of a Toolbox for Compiler Construction called
.i Cocktail
\*([[GrE90\*(]]. The tool statically checks that an attribute grammar
is well-formed\*([<\*([[RaS82\*(]]\*(>]
using an algorithm that incorporates the optimizations described in
\*([[DJL84\*(],JoP88\*(]].
Although this test was proved to be intrinsically exponential in time and space
\*([[JOR75a\*(],JOR75b\*(]]
it showed to execute in reasonable time in practical cases. This has been observed by
other authors, too\*([<\*([[Aug90\*(]]\*(>].
Currently this test assumes that attribution is performed on a tree. It disregards graphs
and cyclic dependencies that can be introduced through the access of non-local attributes.
In order to guarantee termination a dynamic check for cyclic dependencies can be generated,
optionally.
.pp
In this section evaluators for well-formed attribute grammars (WAG) and for ordered
attribute grammars (OAG) are compared with respect to their space and time behaviour.
The evaluators for ordered attribute grammars were generated in two versions: with
and without optimization of attribute storage.
The evaluators for ordered attribute grammars generated by
.i ag
are claimed to be very efficient.
Two attribute grammars have been used in the experiments: Grammar 1 has 381 lines and 195
attribute computation rules (including conditions), grammar 2 has 362 lines and 106 rules.
Only 113 rules and 65 rules, respectively, are specified explicitly, the others are added
automatically by the system as copy rules.
Grammar 2 was derived from grammar 1 by two modifications:
Instead of a separate data structure for the symbol table
the abstract syntax tree was used for this purpose. The computation of label values for
jump statements was moved from the attribute grammar to the intermediate code generator.
The evaluators implement the semantic analysis for a demo language called
.i Minilax
which is a subset of Pascal. Besides semantic analysis, the complete experiment involved a
front-end compiler for this language including lexical analysis, syntax analysis, abstract
syntax tree construction, and the generation of an intermediate code.
.(z L
.sp 0.5
.ce
Table 1: Experimental Results
.sp
.TS
center box tab (;);
c | 2 c 1 c 1 c | 2 c 1 s 1 s 1 s | 2 c | 2 c 1 s | 2 c 1 s
n | c c c | c c c c | c | c c | c c
n | c c c | n n n n | n | n n | n n
n | c c c | n n n n | n | n n | n n
n | c c c | n n n n | n | n n | n n
c | c s s | n n n n | n | n n | n n
n | c c c | n n n n | n | n n | n n
n | c c c | n n n n | n | n n | n n
n | c c c | n n n n | n | n n | n n
c | c s s | n n n n | n | n n | n n.
#;evalu-;gram-;opt.;run time [sec];speed;memory [KB];evaluator size
 ;ator;mar;  ;Parse;Eval;I-Code;total;[lines/sec];heap;stack;[lines];[KB]
_
1;OAG;1;yes;0.58;0.18;0.09;0.85;9421; 789;16.1; 911;6.9
2;OAG;1;no ;0.62;0.21;0.11;0.94;8519;1240;11.5; 730;6.3
3;WAG;1;-  ;0.67;0.87;0.11;1.65;4853;1506;18.8;1808;23.8
_
a;ratio 3/1;1.2;4.8;1.2;1.9;0.5;1.9;1.2;2.0;3.4
_
4;OAG;2;yes;0.58;0.16;0.12;0.86;9311; 789;11.5; 813;6.4
5;OAG;2;no ;0.57;0.16;0.13;0.86;9311; 809;11.5; 609;5.0
6;WAG;2;-  ;0.63;0.36;0.12;1.11;7214;1076;17.5;1236;16.2
_
b;ratio 6/4;1.1;2.3;1.0;1.3;0.8;1.4;1.5;1.5;2.5
.TE
.)z
.pp
The results of six experiments are summarized in Table 1.
Line a gives the ratio of the results obtained by experiment 3 relatively to experiment 1 and
line b gives the ratio of the results obtained by experiment 6 relatively to experiment 4.
The results were obtained on a SPARC station 10 using as input a 8000 line Minilax
program. The implementation language is C and the sources have been compiled with the
command "cc -O".
We measured the CPU times for the three phases of the front-end (Parse: scanning + parsing
+ tree construction, Eval: attribute evaluation, I-Code: intermediate code generation), the
consumption of memory for heap and stack, as well as the sizes of the attribute evaluators.
.pp
In the case of the WAG evaluator for grammar 1 more resources are used in comparison to
the OAG evaluator: Run time is increased by a factor of 4.8, heap space by 1.9, stack space
by 1.2, and the size of the binary evaluator by 3.4. The total run time of the front-end
increases by a factor of 1.9.
In the case of the WAG evaluator for grammar 2 which has the same functionality as grammar
1 the increases are in general not so high:
Run time is increased by a factor of 2.3, heap space by 1.4, stack space
by 1.5, and the size of the binary evaluator by 2.5. The total run time of the front-end
increases by a factor of 1.3.
Although the phase Parse was identical in all experiments its run time varies because of
the different amounts of heap memory that are allocated for the tree.
For a complete compiler, the increase in the total run time will be smaller
depending on the time need by the code generator. A WAG evaluator
consumes more resources than an OAG evaluator. However, nowadays we do have those
resources and the execution speed is still very high (7214 lines/sec). We are
optimistic to reach the performance of OAG evaluators or to do even better, because
well-formed attribute grammars are much easier to write and involve less attributes.
.sh 1 "Related Research"
.lp
During the past 20 years several generators for well-formed attribute grammars have been
constructed:
AG,
CGSG,
CIS,
COPS,
DELTA,
Elegant,
FNC/ERN,
FOLDS,
LINGUA,
NEATS,
R\*UGEN,
Synthesizer Generator,
TALLINN.
The survey book on attribute grammars\*([<\*([[DJL88\*(]]\*(>]
contains many references to those systems.
To our knowledge, only the systems DELTA, LINGUA and Elegant
statically check whether an attribute grammars is well-formed. Some of the other systems
check this property dynamically during attribute evaluation. The underlying data structure
is either the syntax tree or the associated graph of dependencies among the attributes.
Almost all attribute evaluators are rather slow and consume huge amounts of memory
especially if the complete dependency graph is constructed.
.pp
The Elegant system\*([<\*([[Aug90\*(]]\*(>] is remarkable because it is reasonable
efficient. Front-ends generated by Elegant run at a speed of 600 to 820 lines/sec on a
SUN 4/390 and need 500 KB of memory for 1000 lines of input text.
The rather large consumption of memory is due to the complete dependency graph.
According to the author this limits the use of compilers generated by Elegant to modules of
a few thousand lines.
The system can handle so-called pseudo circular attribute grammars and supports the
manipulation of unevaluated attributes by a lazy evaluation technique.
If we do our experiment on a SUN 4 the
.i Minilax
front-end would run at a speed of 5000 lines/sec and consume 135 KB for 1000 lines.
Even if these numbers might change for real applications by a factor of up to two then
still a big gain of efficiency has been achieved by our implementation scheme.
.sh 1 Conclusion
.lp
The presented implementation scheme allows for the generation of evaluators for well-formed
or non circular attribute grammars that are efficient, both in terms of space and time. It
is no longer necessary to use restricted classes of attribute grammars. Moreover,
attribution of trees has been extended in several ways including attribution of graphs,
higher order attribute grammars, and access to non-local attributes.
.pp
The efficiency of the attribute evaluators makes the attribute grammar technology attractive
for real world applications that demand for production quality. The unrestricted class
of well-formed attribute grammars together with the described extensions can increase the
acceptance of attribute grammars as specification technique for semantic analysis.
.pp
Our generator for evaluators of well-formed attribute grammars is an available product.
It is implemented in C and generates evaluators in C, C++, or Modula-2. It is portable and
known to run on commonly used operating systems such as UNIX and MS-DOS.
.pp
Future work will include alternative implementation schemes such as a table-driven
evaluator, the extension of the test for well-formedness to graphs and to non-local
attribute access, performance analysis for a large application, and the development
of a style guide that exploits the possibilities of well-formed attribute grammars
and the presented extensions.
.fi
.sz 12
.[]
.[-
.ds [F Aug90
.ds [A L\*(p] Augusteijn
.ds [T The Elegant Compiler Generator System
.ds [V 461
.ds [J LNCS
.ds [C Berlin
.ds [I Springer Verlag
.nr [P 1
.ds [P 238-254
.ds [D Sep. 1990
.][
.[-
.ds [F DJL84
.ds [A P\*(p] Deransart
.as [A \*(c]M\*(p] Jourdan
.as [A \*(m]B\*(p] Lorho
.ds [T Speeding up Circularity Tests for Attribute Grammars
.ds [V 21
.ds [J Acta Inf.
.nr [P 1
.ds [P 375-391
.ds [D Dec. 1984
.][
.[-
.ds [F DJL88
.ds [A P\*(p] Deransart
.as [A \*(c]M\*(p] Jourdan
.as [A \*(m]B\*(p] Lorho
.ds [T Attribute Grammars - Definitions, Systems and Bibliography
.ds [V 323
.ds [J LNCS
.ds [C Berlin
.ds [I Springer Verlag
.ds [D 1988
.][
.[-
.ds [F GrE90
.ds [A J\*(p] Grosch
.as [A \*(n]H\*(p] Emmelmann
.ds [T A Tool Box for Compiler Construction
.ds [V 477
.ds [J LNCS
.ds [C Berlin
.ds [I Springer Verlag
.nr [P 1
.ds [P 106-116
.ds [D Oct. 1990
.][
.[-
.ds [F Gro92
.ds [A J\*(p] Grosch
.ds [T Transformation of Attributed Trees Using Pattern Matching
.ds [V 641
.ds [J LNCS
.ds [C Berlin
.ds [I Springer Verlag
.nr [P 1
.ds [P 1-15
.ds [D Oct. 1992
.][
.[-
.ds [F Gro
.ds [A J\*(p] Grosch
.ds [T Ag - An Attribute Evaluator Generator
.ds [I CoCoLab Germany
.ds [R Cocktail Document No. 16
.ds [N 16
.][
.[-
.ds [F IRL92
.ds [A IRL
.ds [T Industrial Robot Language, DIN 66312
.ds [I Beuth-Verlag
.ds [C Berlin, to appear
.ds [D 1992
.][
.[-
.ds [F JOR75a
.ds [A M\*(p] Jazayeri
.as [A \*(c]W\*(p]\*(a]F\*(p] Ogden
.as [A \*(m]W\*(p]\*(a]C\*(p] Rounds
.ds [T On the Complexity of Circularity Tests for Attribute Grammars
.ds [J ACM Symp. on Prin. of Programming Languages
.ds [V 2
.nr [P 1
.ds [P 119-129
.ds [D Jan. 1975
.ds [C Palo Alto
.][
.[-
.ds [F JOR75b
.ds [A M\*(p] Jazayeri
.as [A \*(c]W\*(p]\*(a]F\*(p] Ogden
.as [A \*(m]W\*(p]\*(a]C\*(p] Rounds
.ds [T The Intrinsically Exponential Complexity of the Circularity Problem for Attribute Grammars
.ds [J Comm. ACM
.ds [V 18
.nr [P 1
.ds [P 679-706
.ds [D Dec. 1975
.][
.[-
.ds [F JoP88
.ds [A M\*(p] Jourdan
.as [A \*(n]D\*(p] Parigot
.ds [T More on Speeding up Circularity Tests for Attribute Grammars
.ds [R rapport RR-828
.ds [I INRIA
.ds [C Rocquencourt
.ds [D Apr. 1988
.][
.[-
.ds [F Kas80
.ds [A U\*(p] Kastens
.ds [T Ordered Attribute Grammars
.nr [P 1
.ds [P 229-256
.ds [J Acta Inf.
.ds [V 13
.ds [D 1980
.ds [N 3
.][
.[-
.ds [F Kie91
.ds [A K\*(p] Kiessling
.ds [T Entwurf und Implementierung des Frontends eines Modula-3-\\*Ubersetzers
.ds [R Diplomarbeit
.ds [I GMD Forschungsstelle an der Universit\\*at Karlsruhe
.ds [D Apr. 1991
.][
.[-
.ds [F Knu68
.ds [A D\*(p]\*(a]E\*(p] Knuth
.ds [T Semantics of Context-Free Languages
.nr [P 1
.ds [P 127-146
.ds [J Mathematical Systems Theory
.ds [V 2
.ds [D June 1968
.ds [N 2
.][
.[-
.ds [F Mar90
.ds [A M\*(p] Martin
.ds [T Entwurf und Implementierung eines \\*Ubersetzers von Modula-2 nach C
.ds [R Diplomarbeit
.ds [I GMD Forschungsstelle an der Universit\\*at Karlsruhe
.ds [D Feb. 1990
.][
.[-
.ds [F RaS82
.ds [A K\*(p] R\\*aih\\*a
.as [A \*(n]M\*(p] Saarinen
.ds [T Testing Attribute Grammars for Circularity
.ds [V 17
.ds [J Acta Inf.
.nr [P 1
.ds [P 185-192
.ds [D 1982
.][
.[-
.ds [F VSK89
.ds [A H\*(p]\*(a]H\*(p] Vogt
.as [A \*(c]S\*(p]\*(a]D\*(p] Swierstra
.as [A \*(m]M\*(p]\*(a]F\*(p] Kuiper
.ds [T Higher Order Attribute Grammars
.ds [J SI\&GPLAN Notices
.ds [V 24
.ds [N 7
.nr [P 1
.ds [P 131-145
.ds [D July 1989
.][
.[-
.ds [F Vog93
.ds [A H\*(p]\*(a]H\*(p] Vogt
.ds [T Higher Order Attribute Grammars
.ds [I PhD Thesis, University of Utrecht
.ds [D Feb. 1993
.][
.bp 1
.lp
.b Contents
.sp
.xp
